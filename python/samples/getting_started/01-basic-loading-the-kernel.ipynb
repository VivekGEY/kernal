{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Loading of the Kernel\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the notebooks we recommend using Poetry and starting a shell with a virtual environment\n",
    "prepared to use SK.\n",
    "\n",
    "See [DEV_SETUP.md](../../python/DEV_SETUP.md) for more information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if using a Poetry virtual environment, do not run this cell\n",
    "%pip install semantic-kernel==1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our kernel for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Let's get started with the necessary configuration to run Semantic Kernel. For Notebooks, we require a `.env` file with the proper settings for the model you use. You may copy the `.env.example` file from this directory and place it either in this current directory, or in the main semantic-kernel/python directory.\n",
    "\n",
    "If interested, as you learn more about Semantic Kerenl, there are a few other ways to make sure your secrets, keys, and settings are used:\n",
    "\n",
    "- Set the keys/secrets/endpoints as environment variables in your system.\n",
    "- Manually configure the `api_key` or required parameters on either the `OpenAIChatCompletion` or `AzureChatCompletion` constructor with keyword arguments.\n",
    "\n",
    "For now we want to keep things as simple as possible. We will be more explicit and use the `dotenv` library to load the settings.\n",
    "\n",
    "**NOTE: Please make sure to include `GLOBAL_LLM_SERVICE` set to either OpenAI, AzureOpenAI, or HuggingFace in your .env file or environment variables. If this setting is not included, the Service will default to AzureOpenAI.**\n",
    "\n",
    "## Option 1: using OpenAI\n",
    "\n",
    "**Step 2**: Add your [OpenAI Key](https://openai.com/product/) key to either your environment variables or to the `.env` file in the same folder (org Id only if you have multiple orgs):\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_ORG_ID=\"\"\n",
    "OPENAI_CHAT_MODEL_ID=\"\"\n",
    "```\n",
    "The environment variables names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "If using the `.env` file, it is possible to configure the `ServiceSettings` with the `env_file_path` (absolute or relative).\n",
    "\n",
    "```\n",
    "chat_completion = OpenAIChatCompletion(service_id=\"test\", env_file_path=<path_to_file>)\n",
    "```\n",
    "\n",
    "Use \"keyword arguments\" to instantiate an OpenAI Chat Completion service and add it to the kernel:\n",
    "\n",
    "## Option 2: using Azure OpenAI\n",
    "\n",
    "**Step 2**: Add your [Azure Open AI Service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio) settings to either your system's environment variables or to the `.env` file in the same folder:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_TEXT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_API_VERSION=\"...\"\n",
    "```\n",
    "The environment variables names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "If using the `.env` file, please configure the `env_file_path` parameter with a valid path when creating the ChatCompletion class:\n",
    "\n",
    "```\n",
    "chat_completion = AzureChatCompletion(service_id=\"test\", env_file_path=<path_to_file>)\n",
    "```\n",
    "\n",
    "Use \"keyword arguments\" to instantiate an Azure OpenAI Chat Completion service and add it to the kernel:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the kernel for AI requests, the kernel needs some settings like URL and credentials to the AI models.\n",
    "\n",
    "The SDK currently supports OpenAI and Azure OpenAI, among other connectors.\n",
    "\n",
    "If you need an Azure OpenAI key, go [here](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quickstart?pivots=rest-api).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure paths are correct for the imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load our settings and get the LLM service to use for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from services import Service\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "global_llm_service = os.getenv(\"GLOBAL_LLM_SERVICE\")\n",
    "if global_llm_service is None:\n",
    "    global_llm_service = \"AzureOpenAI\"\n",
    "\n",
    "selectedService = Service(global_llm_service.lower())\n",
    "\n",
    "print(f\"Using service type: {selectedService}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our settings and validate that the required ones exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selectedService == Service.AzureOpenAI:\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    chat_deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    base_url = os.getenv(\"AZURE_OPENAI_BASE_URL\")\n",
    "    api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "    assert api_key is not None, \"Azure OpenAI API key is not set\"\n",
    "    assert chat_deployment_name is not None, \"Azure OpenAI Chat deployment name is not set\"\n",
    "elif selectedService == Service.OpenAI:\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    chat_model_id = os.getenv(\"OPENAI_CHAT_MODEL_ID\")\n",
    "    org_id = os.getenv(\"OPENAI_ORG_ID\")\n",
    "\n",
    "    assert api_key is not None, \"OpenAI API key is not set\"\n",
    "    assert chat_model_id is not None, \"OpenAI Chat model ID is not set\"\n",
    "else:\n",
    "    raise ValueError(f\"The {selectedService} service is not valid in this example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "kernel.remove_all_services()\n",
    "\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(\n",
    "            service_id=service_id,\n",
    "            ai_model_id=chat_model_id,\n",
    "            org_id=org_id,\n",
    "            api_key=api_key,\n",
    "        ),\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "            api_key=api_key,\n",
    "            deployment_name=chat_deployment_name,\n",
    "            endpoint=endpoint,\n",
    "            base_url=base_url,\n",
    "            api_version=api_version,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that you're familiar with setting up the Semantic Kernel, let's see [how we can use it to run prompts](02-running-prompts-from-file.ipynb).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "items": [
     {
      "aliases": [
       "frontend"
      ],
      "name": "vscode"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
