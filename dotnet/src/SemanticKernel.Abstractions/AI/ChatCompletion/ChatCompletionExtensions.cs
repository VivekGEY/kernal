// Copyright (c) Microsoft. All rights reserved.

using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading;
using System.Threading.Tasks;

namespace Microsoft.SemanticKernel.AI.ChatCompletion;

/// <summary>
/// Class sponsor that holds extension methods for <see cref="IChatCompletion"/> interface.
/// </summary>
public static class ChatCompletionExtensions
{
    /// <summary>
    /// Get chat multiple chat content choices for the prompt and settings.
    /// </summary>
    /// <remarks>
    /// This should be used when the settings request for more than one choice.
    /// </remarks>
    /// <param name="chatCompletion">Target chat completion</param>
    /// <param name="prompt">The standardized prompt input.</param>
    /// <param name="executionSettings">Request settings for the completion API</param>
    /// <param name="kernel">The <see cref="Kernel"/> containing services, plugins, and other state for use throughout the operation.</param>
    /// <param name="cancellationToken">The <see cref="CancellationToken"/> to monitor for cancellation requests. The default is <see cref="CancellationToken.None"/>.</param>
    /// <returns>List of different chat content choices generated by the remote model</returns>
    public static Task<IReadOnlyList<ChatContent>> GetChatContentsAsync(
        this IChatCompletion chatCompletion,
        string prompt,
        PromptExecutionSettings? executionSettings = null,
        Kernel? kernel = null,
        CancellationToken cancellationToken = default)
    {
        // Try to parse the text as a chat history
        if (XmlPromptParser.TryParse(prompt!, out var nodes) && ChatPromptParser.TryParse(nodes, out var chatHistory))
        {
            return chatCompletion.GetChatContentsAsync(chatHistory, executionSettings, kernel, cancellationToken);
        }

        //Otherwise, use the prompt as the chat system message
        return chatCompletion.GetChatContentsAsync(new ChatHistory(prompt), executionSettings, kernel, cancellationToken);
    }

    /// <summary>
    /// Get a single chat content for the prompt and settings.
    /// </summary>
    /// <param name="chatCompletion"></param>
    /// <param name="prompt">The standardized prompt input.</param>
    /// <param name="executionSettings">Request settings for the completion API</param>
    /// <param name="kernel">The <see cref="Kernel"/> containing services, plugins, and other state for use throughout the operation.</param>
    /// <param name="cancellationToken">The <see cref="CancellationToken"/> to monitor for cancellation requests. The default is <see cref="CancellationToken.None"/>.</param>
    /// <returns>List of different chat results generated by the remote model</returns>
    public static async Task<ChatContent> GetChatContentAsync(
        this IChatCompletion chatCompletion,
        string prompt,
        PromptExecutionSettings? executionSettings = null,
        Kernel? kernel = null,
        CancellationToken cancellationToken = default)
        => (await chatCompletion.GetChatContentsAsync(prompt, executionSettings, kernel, cancellationToken).ConfigureAwait(false))
            .Single();

    /// <summary>
    /// Get a single chat content for the chat history and settings provided.
    /// </summary>
    /// <param name="chatCompletion"></param>
    /// <param name="chatHistory">The chat history to complete.</param>
    /// <param name="executionSettings">Request settings for the completion API</param>
    /// <param name="kernel">The <see cref="Kernel"/> containing services, plugins, and other state for use throughout the operation.</param>
    /// <param name="cancellationToken">The <see cref="CancellationToken"/> to monitor for cancellation requests. The default is <see cref="CancellationToken.None"/>.</param>
    /// <returns>List of different chat results generated by the remote model</returns>
    public static async Task<ChatContent> GetChatContentAsync(
        this IChatCompletion chatCompletion,
        ChatHistory chatHistory,
        PromptExecutionSettings? executionSettings = null,
        Kernel? kernel = null,
        CancellationToken cancellationToken = default)
        => (await chatCompletion.GetChatContentsAsync(chatHistory, executionSettings, kernel, cancellationToken).ConfigureAwait(false))
            .Single();

    /// <summary>
    /// Get streaming chat contents for the chat history provided using the specified request settings.
    /// </summary>
    /// <exception cref="NotSupportedException">Throws if the specified type is not the same or fail to cast</exception>
    /// <param name="chatCompletion">Target chat completion</param>
    /// <param name="prompt">The standardized prompt input.</param>
    /// <param name="executionSettings">Request settings for the completion API</param>
    /// <param name="kernel">The <see cref="Kernel"/> containing services, plugins, and other state for use throughout the operation.</param>
    /// <param name="cancellationToken">The <see cref="CancellationToken"/> to monitor for cancellation requests. The default is <see cref="CancellationToken.None"/>.</param>
    /// <returns>Streaming list of different completion streaming string updates generated by the remote model</returns>
    public static IAsyncEnumerable<StreamingChatContent> GetStreamingChatContentsAsync(
        this IChatCompletion chatCompletion,
        string prompt,
        PromptExecutionSettings? executionSettings = null,
        Kernel? kernel = null,
        CancellationToken cancellationToken = default)
    {
        // Try to parse the text as a chat history
        if (XmlPromptParser.TryParse(prompt!, out var nodes) && ChatPromptParser.TryParse(nodes, out var chatHistory))
        {
            return chatCompletion.GetStreamingChatContentsAsync(chatHistory, executionSettings, kernel, cancellationToken);
        }

        //Otherwise, use the prompt as the chat system message
        return chatCompletion.GetStreamingChatContentsAsync(new ChatHistory(prompt), executionSettings, kernel, cancellationToken);
    }
}
