{
  "OpenAI": {
    "ServiceId": "text-davinci-003",
    "ModelId": "text-davinci-003",
    "ChatModelId": "gpt-3.5-turbo",
    "ApiKey": ""
  },
  "AzureOpenAI": {
    "ServiceId": "azure-text-davinci-003",
    "DeploymentName": "text-davinci-003",
    "ChatDeploymentName": "gpt-4",
    "Endpoint": "",
    "ApiKey": ""
  },
  "OpenAIEmbeddings": {
    "ServiceId": "text-embedding-ada-002",
    "ModelId": "text-embedding-ada-002",
    "ApiKey": ""
  },
  "AzureOpenAIEmbeddings": {
    "ServiceId": "azure-text-embedding-ada-002",
    "DeploymentName": "text-embedding-ada-002",
    "Endpoint": "",
    "ApiKey": ""
  },
  "HuggingFace": {
    "ApiKey": ""
  },
  "Bing": {
    "ApiKey": ""
  },
  "Postgres": {
    "ConnectionString": ""
  },
  "MultiConnector": {
    "OobaboogaEndPoint": "http://localhost",
    "OobaboogaCompletions": [
      //{
      //  "Name": "TheBloke_orca_mini_3B-GGML",
      //  "BlockingPort": 5000,
      //  "StreamingPort": 5010,
      //  "MaxTokens": 2048,
      //  "CostPer1000Token": 0.0003,
      //  "PromptTransform": {
      //    "Template": "### System:\nYou are an AI assistant that follows instruction extremely well. Help as much as you can.\n\n### User:\n{0}\n\n### Response:"
      //  }
      //},
      //{
      //  "Name": "togethercomputer_RedPajama-INCITE-Chat-3B-v1",
      //  "BlockingPort": 5001,
      //  "StreamingPort": 5011,
      //  "MaxTokens": 2048,
      //  "CostPer1000Token": 0.0004,
      //  "PromptTransform": {
      //    "Template": "<human>: [Instruction]\n{0}\n<bot>:"
      //  }
      //},
      //{
      //  "Name": "TheBloke_StableBeluga-7B-GGML",
      //  "BlockingPort": 5002,
      //  "StreamingPort": 5012,
      //  "MaxTokens": 4096,
      //  "CostPer1000Token": 0.0005,
      //  "PromptTransform": {
      //    "Template": "### System:\nThis is a system prompt, please behave and help the user.\n\n### User:\n{0}\n\n### Assistant:"
      //  }
      //}
      //,
      {
        "Name": "TheBloke_StableBeluga-13B-GGML",
        "BlockingPort": 5003,
        "StreamingPort": 5013,
        "MaxTokens": 4096,
        "CostPer1000Token": 0.007,
        "PromptTransform": {
          "Template": "### System:\nThis is a system prompt, please behave and help the user.\n\n### User:\n{0}\n\n### Assistant:"
        }
      }
      //,
      //{
      //  "Name": "TheBloke_upstage-llama-30b-instruct-2048-GGML",
      //  //"EndPoint": "http://x.x.x.x", Most probably you won't host that model on the same machine as the tests runner and the rest of the models
      //  "BlockingPort": 5004,
      //  "StreamingPort": 5014,
      //  "MaxTokens": 2048,
      //  "CostPer1000Token": 0.001,
      //  "PromptTransform": {
      //    "Template": "### System:\nThis is a system prompt, please behave and help the user.\n\n### User:\n{0}\n\n### Assistant:"
      //  }
      }
    ]
  }
}
