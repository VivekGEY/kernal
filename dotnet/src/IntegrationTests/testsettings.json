{
  "OpenAI": {
    "ServiceId": "text-davinci-003",
    "ModelId": "text-davinci-003",
    "ChatModelId": "gpt-3.5-turbo",
    "ApiKey": ""
  },
  "AzureOpenAI": {
    "ServiceId": "azure-text-davinci-003",
    "DeploymentName": "text-davinci-003",
    "ChatDeploymentName": "gpt-4",
    "Endpoint": "",
    "ApiKey": ""
  },
  "OpenAIEmbeddings": {
    "ServiceId": "text-embedding-ada-002",
    "ModelId": "text-embedding-ada-002",
    "ApiKey": ""
  },
  "AzureOpenAIEmbeddings": {
    "ServiceId": "azure-text-embedding-ada-002",
    "DeploymentName": "text-embedding-ada-002",
    "Endpoint": "",
    "ApiKey": ""
  },
  "HuggingFace": {
    "ApiKey": ""
  },
  "Bing": {
    "ApiKey": ""
  },
  "Postgres": {
    "ConnectionString": ""
  },
  "MultiConnector": {
    "OobaboogaEndPoint": "http://localhost",
    "GlobalParameters": {
      "System": "User is now playing a game where he is writing messages in the form of semantic functions. That means you are expected to strictly answer with a completion of his message, without adding any additional comments.",
      "UserPreamble": "Let's play a game: please read the following instructions, and simply answer with a completion of my message, don't add any personal comments."
    },
    "OobaboogaCompletions": [
      {
        "Name": "TheBloke_orca_mini_3B-GGML",
        "BlockingPort": 5000,
        "StreamingPort": 5010,
        "MaxTokens": 2048,
        "CostPer1000Token": 0.0003,
        "PromptTransform": {
          "Template": "### System:\nYou are an AI assistant that follows instruction extremely well. Help as much as you can.\n{System}\n\n### User:\n{0}\n\n### Assistant:"
        }
      },
      {
        "Name": "togethercomputer_RedPajama-INCITE-Chat-3B-v1",
        "BlockingPort": 5001,
        "StreamingPort": 5011,
        "MaxTokens": 2048,
        "CostPer1000Token": 0.0004,
        "PromptTransform": {
          "Template": "<human>: {UserPreamble}[Instruction]\n{0}\n<bot>:"
        }
      },
      {
        "Name": "TheBloke_StableBeluga-7B-GGML",
        "BlockingPort": 5002,
        "StreamingPort": 5012,
        "MaxTokens": 4096,
        "CostPer1000Token": 0.0005,
        "PromptTransform": {
          "Template": "### System:\nThis is a system prompt, please behave and help the user.\n{System}\n\n### User:\n{0}\n\n### Assistant:"
        }
      },
      {
        "Name": "TheBloke_StableBeluga-13B-GGML",
        "BlockingPort": 5003,
        "StreamingPort": 5013,
        "MaxTokens": 4096,
        "CostPer1000Token": 0.0007,
        "PromptTransform": {
          "Template": "### System:\nThis is a system prompt, please behave and help the user.\n{System}\n\n### User:\n{0}\n\n### Assistant:"
        }
      },
      {
        "Name": "TheBloke_upstage-llama-30b-instruct-2048-GGML",
        //"EndPoint": "http://x.x.x.x", Most probably you won't host that model on the same machine as the tests runner and the rest of the models
        "BlockingPort": 5004,
        "StreamingPort": 5014,
        "MaxTokens": 2048,
        "CostPer1000Token": 0.001,
        "PromptTransform": {
          "Template": "### System:\r\n{System}\r\n\r\n### User:\r\n{0}\n\n### Assistant:\n"
        }
      }
    ]
  }
}
