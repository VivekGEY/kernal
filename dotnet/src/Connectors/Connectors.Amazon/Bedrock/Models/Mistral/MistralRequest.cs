// Copyright (c) Microsoft. All rights reserved.

using System.Text.Json.Serialization;
using Amazon.BedrockRuntime.Model;
using Connectors.Amazon.Core.Requests;

namespace Connectors.Amazon.Models.Mistral;

/// <summary>
/// Mistral request bodies.
/// </summary>
public static class MistralRequest
{
    /// <summary>
    /// Text generation request structure for Mistral to be passed into the InvokeModelRequest body.
    /// </summary>
    [Serializable]
    public sealed class MistralTextGenerationRequest : ITextGenerationRequest
    {
        /// <summary>
        /// (Required) The prompt that you want to pass to the model, as shown in the following example.
        /// </summary>
        [JsonPropertyName("prompt")]
        public required string Prompt { get; set; }
        /// <summary>
        /// Specify the maximum number of tokens to use in the generated response. The model truncates the response once the generated text exceeds max_tokens
        /// </summary>
        [JsonPropertyName("max_tokens")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public int? MaxTokens { get; set; }
        /// <summary>
        /// A list of stop sequences that if generated by the model, stops the model from generating further output.
        /// </summary>
        [JsonPropertyName("stop")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public IList<string>? StopSequences { get; set; } = new List<string>();
        /// <summary>
        /// Controls the randomness of predictions made by the model.
        /// </summary>
        [JsonPropertyName("temperature")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public double? Temperature { get; set; }
        /// <summary>
        /// Controls the diversity of text that the model generates by setting the percentage of most-likely candidates that the model considers for the next token.
        /// </summary>
        [JsonPropertyName("top_p")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public double? TopP { get; set; }
        /// <summary>
        /// Controls the number of most-likely candidates that the model considers for the next token.
        /// </summary>
        [JsonPropertyName("top_k")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public int? TopK { get; set; }

        string ITextGenerationRequest.InputText => this.Prompt;
    }

    internal sealed class MistralChatCompletionRequest
    {
        [JsonPropertyName("model")]
        public string Model { get; set; }

        [JsonPropertyName("messages")]
        public IList<MistralChatMessage> Messages { get; set; } = [];

        [JsonPropertyName("temperature")]
        public double Temperature { get; set; } = 0.7;

        [JsonPropertyName("top_p")]
        public double TopP { get; set; } = 1;

        [JsonPropertyName("max_tokens")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public int MaxTokens { get; set; }

        [JsonPropertyName("stream")]
        public bool Stream { get; set; }

        [JsonPropertyName("safe_prompt")]
        public bool SafePrompt { get; set; }

        [JsonPropertyName("tools")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public IList<MistralTool>? Tools { get; set; }

        [JsonPropertyName("tool_choice")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public string? ToolChoice { get; set; }

        [JsonPropertyName("random_seed")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public int? RandomSeed { get; set; }

        /// <summary>
        /// Construct an instance of Chat Completion.
        /// </summary>
        /// <param name="model">ID of the model to use.</param>
        [JsonConstructor]
        internal MistralChatCompletionRequest(string model)
        {
            this.Model = model;
        }

        /// <summary>
        /// Add a tool to the request.
        /// </summary>
        internal void AddTool(MistralTool tool)
        {
            this.Tools ??= [];
            this.Tools.Add(tool);
        }

        /// <summary>
        /// Add a message to the request.
        /// </summary>
        /// <param name="message"></param>
        internal void AddMessage(MistralChatMessage message)
        {
            this.Messages.Add(message);
        }
    }
    /// <summary>
    /// Mistral Chat message object.
    /// </summary>
    public class MistralChatMessage : Message
    {
        /// <summary>
        /// Role of the message (system, user, or assistant).
        /// </summary>
        [JsonPropertyName("role")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public string? Role { get; set; }
        /// <summary>
        /// The content of the chat completion message.
        /// </summary>
        [JsonPropertyName("content")]
        public string? Content { get; set; }
        /// <summary>
        /// List of tool calls for the chat message.
        /// </summary>
        [JsonPropertyName("tool_calls")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public IList<MistralToolCall>? ToolCalls { get; set; }

        /// <summary>
        /// Construct an instance of <see cref="MistralChatMessage"/>.
        /// </summary>
        /// <param name="role">If provided must be one of: system, user, assistant</param>
        /// <param name="content">Content of the chat message</param>
        [JsonConstructor]
        internal MistralChatMessage(string? role, string? content)
        {
            if (role is not null and not "system" and not "user" and not "assistant" and not "tool")
            {
                throw new ArgumentException($"Role must be one of: system, user, assistant or tool. {role} is an invalid role.", nameof(role));
            }

            this.Role = role;
            this.Content = content;
        }
    }
    /// <summary>
    /// Mistral tool call object.
    /// </summary>
    public class MistralToolCall
    {
        /// <summary>
        /// Identification of the tool.
        /// </summary>
        [JsonPropertyName("id")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public string? Id { get; set; }
        /// <summary>
        /// Function of the tool.
        /// </summary>
        [JsonPropertyName("function")]
        [JsonIgnore(Condition = JsonIgnoreCondition.WhenWritingNull)]
        public MistralFunction? Function { get; set; }
    }
    /// <summary>
    /// Mistral Text Response body.
    /// </summary>
    [Serializable]
    public class MistralTextResponse
    {
        /// <summary>
        /// A list of outputs from the model.
        /// </summary>
        [JsonPropertyName("outputs")]
        public List<Output>? Outputs { get; set; }
        /// <summary>
        /// Output parameters for the list of outputs of the text response.
        /// </summary>
        public class Output
        {
            /// <summary>
            /// The text that the model generated.
            /// </summary>
            [JsonPropertyName("text")]
            public string? Text { get; set; }
            /// <summary>
            /// The reason why the response stopped generating text.
            /// </summary>
            [JsonPropertyName("stop_reason")]
            public string? StopReason { get; set; }
        }
    }
}
