{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3c93ac5b",
      "metadata": {},
      "source": [
        "# Running Native Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebcabb91",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "40201641",
      "metadata": {},
      "source": [
        "Two of the previous notebooks showed how to [execute semantic functions inline](./03-running-semantic-function-inline.ipynb) and how to [run prompts from a file](./02-running-prompts-from-file.ipynb).\n",
        "\n",
        "In this notebook, we'll show how to use native functions from a file. We will also show how to call semantic functions from native functions.\n",
        "\n",
        "This can be useful in a few scenarios:\n",
        "\n",
        "* Writing logic around how to run a prompt that changes the prompt's outcome.\n",
        "* Using external data sources to gather data to concatenate into your prompt.\n",
        "* Validating user input data prior to sending it to the LLM prompt.\n",
        "\n",
        "Native functions are defined using standard Python code. The structure is simple, but not well documented at this point.\n",
        "\n",
        "The following examples are intended to help guide new users towards successful native & semantic function use with the Python framework."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d90b0c13",
      "metadata": {},
      "source": [
        "Prepare a semantic kernel instance first, loading also the AI service settings defined in the [Setup notebook](00-getting-started.ipynb):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da651d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3712b7c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import semantic_kernel as sk\n",
        "from semantic_kernel.ai.open_ai import AzureTextCompletion, OpenAITextCompletion\n",
        "\n",
        "kernel = sk.Kernel()\n",
        "\n",
        "useAzureOpenAI = False\n",
        "\n",
        "# Configure AI service used by the kernel\n",
        "if useAzureOpenAI:\n",
        "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
        "    kernel.config.add_text_backend(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))\n",
        "else:\n",
        "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
        "    kernel.config.add_text_backend(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "186767f8",
      "metadata": {},
      "source": [
        "Let's create a function that gives us a random number between 3 and a user input as the upper limit. We'll use this number to create 3-x paragraphs of text when passed to a semantic function.\n",
        "\n",
        "For this example, we will create the following directory structure:\n",
        "\n",
        "```txt\n",
        "project-root/\n",
        "├── __main__.py\n",
        "└── skills/\n",
        "    └── NumberGenerator/\n",
        "        └── native_function.py\n",
        "    └── WriterSkill/\n",
        "        └── CorgiStory/\n",
        "            └── skprompt.txt\n",
        "            └── config.json\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "589733c5",
      "metadata": {},
      "source": [
        "First, let's create our native function.\n",
        "Add the following code to native_function.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae29c207",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from semantic_kernel.skill_definition import sk_function\n",
        "\n",
        "class GenerateNumberSkill:\n",
        "    \"\"\"\n",
        "    Description: Generate a number between 3-x.\n",
        "    \"\"\"\n",
        "\n",
        "    @sk_function(\n",
        "        description=\"Generate a random number between 3-x\",\n",
        "        name=\"GenerateNumber\"\n",
        "    )\n",
        "    def generate_number(self, input: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate a number between 3-<input>\n",
        "        Example:\n",
        "            \"8\" => rand(3,8)\n",
        "        Args:\n",
        "            input -- The upper limit for the random number generation\n",
        "        Returns:\n",
        "            int value\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return str(random.randint(3, input)) \n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid input {input}\")\n",
        "            raise e"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "f26b90c4",
      "metadata": {},
      "source": [
        "Next, let's create a semantic function that accepts a number as `{{$INPUT}}` and generates that number of paragraphs about two Corgis on an adventure.\n",
        "\n",
        "Add the following prompt to our `skprompt.txt` file.\n",
        "\n",
        "```\n",
        "Write a short story about two Corgis on an adventure.\n",
        "The storey must be:\n",
        "- G rated\n",
        "- Have a positive message\n",
        "- No sexism, racism or other bias/bigotry\n",
        "- Be exactly {{$input}} paragraphs long\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "703ebf87",
      "metadata": {},
      "source": [
        "...and update the config.json file\n",
        "\n",
        "```\n",
        "{\n",
        "  \"schema\": 1,\n",
        "  \"type\": \"completion\",\n",
        "  \"description\": \"Generate a story about two Corgis\",\n",
        "  \"completion\": {\n",
        "    \"max_tokens\": 500,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_p\": 0.5\n",
        "  },\n",
        "  \"default_backends\": [\n",
        "    \"text-davinci-003\"\n",
        "  ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5485f3f0",
      "metadata": {},
      "source": [
        "Finally, we're ready to setup our script to execute the functions. Open the `__main__.py` file and add the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b0e3b0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import semantic_kernel as sk\n",
        "from semantic_kernel.ai.open_ai import OpenAITextCompletion, AzureTextCompletion\n",
        "\n",
        "\n",
        "def main(input):\n",
        "    # Setup Kernel\n",
        "    kernel = sk.Kernel()\n",
        "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
        "    kernel.config.add_text_backend(\"text-davinci-003\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))\n",
        "\n",
        "    base_skills_directory = os.path.abspath(os.path.join(os.path.dirname(__file__), \"./skills/\"))\n",
        "\n",
        "    # Import native skill\n",
        "    number_generator = kernel.import_native_skill_from_directory(base_skills_directory, \"NumberGenerator\"),\n",
        "\n",
        "    # Import semantic skill\n",
        "    story_generator = kernel.import_semantic_skill_from_directory(base_skills_directory, \"WriterSkill\")\n",
        "\n",
        "    # Run the number generator\n",
        "    number_result = number_generator.invoke(input=input)\n",
        "\n",
        "    # Pass the output to the semantic story function\n",
        "    story_generator.invoke(input=number_result)\n",
        "\n",
        "    print(story_generator)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) <= 1:\n",
        "        print(\"This script requires one input, which should be an integer. Example: `python __main__.py 8`\")\n",
        "    else:\n",
        "        main(sys.argv[1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4777f447",
      "metadata": {},
      "source": [
        "Run the script with `python __main__.py 8` and it will create a story between 3-8 paragraphs."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8ef29d16",
      "metadata": {},
      "source": [
        "## Context Variables\n",
        "\n",
        "Let's expand on our example to add a second input to both the native and the semantic functions.\n",
        "\n",
        "For the native function, we'll introduce the lower limit variable. This means that a user will input two numbers and the NumberGenerator function will pick a number between the first and second input.\n",
        "\n",
        "First, let's update our `__main__.py` file to accept the user input and pass the variables to the native and semantic functions. This will leverage the `semantic_kernel.ContextVariables` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fac37bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import semantic_kernel as sk\n",
        "from semantic_kernel.ai.open_ai import OpenAITextCompletion, AzureTextCompletion\n",
        "\n",
        "\n",
        "def main(min: str, max: str, language: str):\n",
        "    # Setup Kernel\n",
        "    kernel = sk.Kernel()\n",
        "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
        "    kernel.config.add_text_backend(\"text-davinci-003\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))\n",
        "\n",
        "    base_skills_directory = os.path.abspath(os.path.join(os.path.dirname(__file__), \"./skills/\"))\n",
        "\n",
        "    # Import native skill\n",
        "    number_generator = kernel.import_native_skill_from_directory(base_skills_directory, \"NumberGenerator\"),\n",
        "\n",
        "    # Import semantic skill\n",
        "    story_generator = kernel.import_semantic_skill_from_directory(base_skills_directory, \"WriterSkill\")\n",
        "\n",
        "\n",
        "    context_variables = sk.ContextVariables(variables={\n",
        "        \"min\": min,\n",
        "        \"max\": max,\n",
        "        \"language\": language,\n",
        "        \"paragraph_count\": \"\"\n",
        "    })\n",
        "\n",
        "    # Run the number generator\n",
        "    context_variables['paragraph_count'] = number_generator.invoke(variables=context_variables)\n",
        "\n",
        "    # Pass the output to the semantic story function\n",
        "    story_generator.invoke(variables=context_variables)\n",
        "\n",
        "    print(story_generator)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) <= 3:\n",
        "        print(\"This script requires three inputs. The first two are min, max, which should be integers. The third is the language to write in. Example: `python __main__.py 4 10 english`\")\n",
        "    else:\n",
        "        main(sys.argv[1], sys.argv[2], sys.argv[3])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ff3aacff",
      "metadata": {},
      "source": [
        "Now that we can accept additional inputs from the user and we have those wired up to the functions, we need to update those functions to accept these new arguments.\n",
        "\n",
        "Let's start with the native function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8128c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from semantic_kernel.skill_definition import sk_function\n",
        "from semantic_kernel import SKContext\n",
        "\n",
        "class GenerateNumberSkill:\n",
        "    \"\"\"\n",
        "    Description: Generate a number between 3-x.\n",
        "    \"\"\"\n",
        "\n",
        "    @sk_function(\n",
        "        description=\"Generate a random number between min and max\",\n",
        "        name=\"GenerateNumber\"\n",
        "    )\n",
        "    def generate_number(self, context: SKContext) -> str:\n",
        "        \"\"\"\n",
        "        Generate a number between min-max\n",
        "        Example:\n",
        "            min=\"4\" max=\"10\" => rand(4,8)\n",
        "        Args:\n",
        "            min -- The lower limit for the random number generation\n",
        "            max -- The upper limit for the random number generation\n",
        "        Returns:\n",
        "            int value\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return str(random.randint(int(context[\"min\"]), int(context[\"max\"]))) \n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid input {context['min']} {context['max']}\")\n",
        "            raise e"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c7fb4cc6",
      "metadata": {},
      "source": [
        "Finally, we'll update our semantic function to handle the new inputs.\n",
        "\n",
        "```\n",
        "Write a short story about two Corgis on an adventure.\n",
        "The storey must be:\n",
        "- G rated\n",
        "- Have a positive message\n",
        "- No sexism, racism or other bias/bigotry\n",
        "- Be exactly {{$paragraph_count}} paragraphs long\n",
        "- Be written in this language: {{$language}}\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3d340138",
      "metadata": {},
      "source": [
        "Great! We're all set, give it a test: \n",
        "\n",
        "```bash\n",
        "python __main__.py 4 10 english\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ef6c2996",
      "metadata": {},
      "source": [
        "## Calling Semantic Functions from Native Functions with Context Variables\n",
        "\n",
        "One more example to show here is how we can modify this code to make the native function directly call the semantic function.\n",
        "\n",
        "Note that in this case, we'd likely want to rename our native function to better represent the intent of producing the story, not just generating a number. However, for simplicity of example, we'll leave the function names as-is.\n",
        "\n",
        "First, let's trim down our `__main__.py` file to remove the calls to our semantic function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb8a4bb5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import semantic_kernel as sk\n",
        "from semantic_kernel.ai.open_ai import OpenAITextCompletion, AzureTextCompletion\n",
        "\n",
        "\n",
        "def main(min: str, max: str, language: str):\n",
        "    # Setup Kernel\n",
        "    kernel = sk.Kernel()\n",
        "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
        "    kernel.config.add_text_backend(\"text-davinci-003\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))\n",
        "\n",
        "    base_skills_directory = os.path.abspath(os.path.join(os.path.dirname(__file__), \"./skills/\"))\n",
        "\n",
        "    # Import native skill\n",
        "    number_generator = kernel.import_native_skill_from_directory(base_skills_directory, \"NumberGenerator\"),\n",
        "\n",
        "    # Import semantic skill.\n",
        "    # This still needs to get imported into the kernel even if we're not calling it in this file.\n",
        "    story_generator = kernel.import_semantic_skill_from_directory(base_skills_directory, \"WriterSkill\")\n",
        "\n",
        "\n",
        "    context_variables = sk.ContextVariables(variables={\n",
        "        \"min\": min,\n",
        "        \"max\": max,\n",
        "        \"language\": language,\n",
        "        \"paragraph_count\": \"\"\n",
        "    })\n",
        "\n",
        "    # Run the number generator\n",
        "    story_generator = number_generator.invoke(variables=context_variables)\n",
        "\n",
        "    print(story_generator)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    if len(sys.argv) <= 3:\n",
        "        print(\"This script requires three inputs. The first two are min, max, which should be integers. The third is the language to write in. Example: `python __main__.py 4 10 english`\")\n",
        "    else:\n",
        "        main(sys.argv[1], sys.argv[2], sys.argv[3])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "849509c1",
      "metadata": {},
      "source": [
        "Next, we'll update our native function to call our semantic function and return the value of the semantic function's output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71d7548",
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from semantic_kernel.skill_definition import sk_function\n",
        "from semantic_kernel import SKContext\n",
        "\n",
        "class GenerateNumberSkill:\n",
        "    \"\"\"\n",
        "    Description: Generate a number between 3-x.\n",
        "    \"\"\"\n",
        "\n",
        "    @sk_function(\n",
        "        description=\"Generate a random number between min and max\",\n",
        "        name=\"GenerateNumber\"\n",
        "    )\n",
        "    def generate_number(self, context: SKContext) -> str:\n",
        "        \"\"\"\n",
        "        Generate a number between min-max\n",
        "        Example:\n",
        "            min=\"4\" max=\"10\" => rand(4,8)\n",
        "        Args:\n",
        "            min -- The lower limit for the random number generation\n",
        "            max -- The upper limit for the random number generation\n",
        "        Returns:\n",
        "            int value\n",
        "        \"\"\"\n",
        "        try:\n",
        "            context['paragraph_count'] = str(random.randint(int(context[\"min\"]), int(context[\"max\"]))) \n",
        "            return context.skills.get_semantic_function(\"WriterSkill\", \"CorgiStory\").invoke(variables=context.variables)\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid input {context['min']} {context['max']}\")\n",
        "            raise e"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
