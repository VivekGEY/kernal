{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "# How to run a semantic skills from file\n",
    "Now that you're familiar with Kernel basics, let's see how the kernel allows you to run Semantic Skills and Semantic Functions stored on disk. \n",
    "\n",
    "A Semantic Skill is a collection of Semantic Functions, where each function is defined with natural language that can be provided with a text file. \n",
    "\n",
    "Refer to our [glossary](https://github.com/microsoft/semantic-kernel/blob/main/docs/GLOSSARY.md) for an in-depth guide to the terms.\n",
    "\n",
    "The repository includes some examples under the [samples](https://github.com/microsoft/semantic-kernel/tree/main/samples) folder.\n",
    "\n",
    "For instance, [this](../../skills/FunSkill/Joke/skprompt.txt) is the **Joke function** part of the **FunSkill skill**:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "```\n",
    "WRITE EXACTLY ONE JOKE or HUMOROUS STORY ABOUT THE TOPIC BELOW.\n",
    "JOKE MUST BE:\n",
    "- G RATED\n",
    "- WORKPLACE/FAMILY SAFE\n",
    "NO SEXISM, RACISM OR OTHER BIAS/BIGOTRY.\n",
    "BE CREATIVE AND FUNNY. I WANT TO LAUGH.\n",
    "+++++\n",
    "{{$input}}\n",
    "+++++\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "Note the special **`{{$input}}`** token, which is a variable that is automatically passed when invoking the function, commonly referred to as a \"function parameter\". \n",
    "\n",
    "We'll explore later how functions can accept multiple variables, as well as invoke other functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "\n",
    "In the same folder you'll notice a second [config.json](../../skills/FunSkill/Joke/config.json) file. The file is optional, and is used to set some parameters for large language models like Temperature, TopP, Stop Sequences, etc.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"schema\": 1,\n",
    "  \"type\": \"completion\",\n",
    "  \"description\": \"Generate a funny joke\",\n",
    "  \"completion\": {\n",
    "    \"max_tokens\": 500,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.5\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "Given a semantic function defined by these files, this is how to load and use a file based semantic function.\n",
    "\n",
    "Load and configure the kernel, as usual, loading also the AI backend settings defined in the [Setup notebook](0-AI-settings.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "kernel = sk.KernelBuilder.create_kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "model = \"text-davinci-003\"\n",
    "\n",
    "# Configure AI backend used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.config.add_azure_openai_completion_backend(\"davinci\", model, endpoint, api_key)\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.config.add_openai_completion_backend(\"davinci\", model, api_key, org_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "Import the skill and all its functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# note: using skills from the skill folder\n",
    "import os\n",
    "\n",
    "skills_directory = \"../../skills\"\n",
    "skill = kernel.import_semantic_skill_from_directory(skills_directory, \"FunSkill\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "How to use the skill functions, e.g. generate a joke about \"*time travel to dinosaur age*\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "result = await kernel.run_async(\"time travel to dinosaur age\", skill[\"Joke\"])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "source": [
    "Great, now that you know how to load a skill from disk, let's show how you can [create and run a semantic function inline.](./3-semantic-function-inline.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "CONFIG_PATH = \"../../skills/FunSkill/Joke/config.json\"\n",
    "PROMPT_PATH = \"../../skills/FunSkill/Joke/skprompt.txt\"\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config_data = json.load(f)\n",
    "\n",
    "with open(PROMPT_PATH) as f:\n",
    "    prompt_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.semantic_functions.prompt_template import PromptTemplate\n",
    "from semantic_kernel.semantic_functions.prompt_template_config import (\n",
    "    PromptTemplateConfig,\n",
    ")\n",
    "from semantic_kernel.semantic_functions.semantic_function_config import (\n",
    "    SemanticFunctionConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PromptTemplateConfig()\n",
    "config.schema = config_data.get(\"schema\")\n",
    "config.type = config_data.get(\"type\")\n",
    "config.description = config_data.get(\"description\")\n",
    "\n",
    "# Some skills may not have all completion parameters defined\n",
    "config.completion = PromptTemplateConfig.CompletionConfig()\n",
    "completition_dict = config_data[\"completion\"]\n",
    "config.completion.temperature = completition_dict.get(\"temperature\")\n",
    "config.completion.top_p = completition_dict.get(\"top_p\")\n",
    "config.completion.presence_penalty = completition_dict.get(\"presence_penalty\")\n",
    "config.completion.frequency_penalty = completition_dict.get(\"frequency_penalty\")\n",
    "config.completion.max_tokens = completition_dict.get(\"max_tokens\")\n",
    "config.completion.stop_sequences = completition_dict.get(\"stop_sequences\")\n",
    "config.default_backends = config_data.get(\"default_backends\")\n",
    "\n",
    "# Some skills may not have input parameters defined\n",
    "if config_data.get(\"input\") is not None:\n",
    "    config.input = PromptTemplateConfig.InputConfig()\n",
    "    config.input.parameters = []\n",
    "    for parameter in config_data[\"input\"][\"parameters\"]:\n",
    "        config.input.parameters.append(\n",
    "            PromptTemplateConfig.InputParameter(\n",
    "                parameter[\"name\"],\n",
    "                parameter[\"description\"],\n",
    "                parameter[\"default_value\"],\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Prompt Template\n",
    "template = PromptTemplate(prompt_data, config, kernel.prompt_template_engine)\n",
    "\n",
    "# Prepare lambda wrapping AI logic\n",
    "function_config = SemanticFunctionConfig(config, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.register_semantic_function(\"FunSkill\", \"Joke\", function_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_config.prompt_template_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.ai.ai_exception import AIException\n",
    "from semantic_kernel.ai.complete_request_settings import CompleteRequestSettings\n",
    "from semantic_kernel.ai.open_ai.services.azure_text_completion import (\n",
    "    AzureTextCompletion,\n",
    ")\n",
    "from semantic_kernel.ai.open_ai.services.open_ai_text_completion import (\n",
    "    OpenAITextCompletion,\n",
    ")\n",
    "from semantic_kernel.configuration.backend_types import BackendType\n",
    "from semantic_kernel.configuration.kernel_config import KernelConfig\n",
    "from semantic_kernel.diagnostics.verify import Verify\n",
    "from semantic_kernel.kernel_base import KernelBase\n",
    "from semantic_kernel.kernel_exception import KernelException\n",
    "from semantic_kernel.memory.semantic_text_memory_base import SemanticTextMemoryBase\n",
    "from semantic_kernel.orchestration.context_variables import ContextVariables\n",
    "from semantic_kernel.orchestration.sk_context import SKContext\n",
    "from semantic_kernel.orchestration.sk_function import SKFunction\n",
    "from semantic_kernel.orchestration.sk_function_base import SKFunctionBase\n",
    "from semantic_kernel.semantic_functions.prompt_template import PromptTemplate\n",
    "from semantic_kernel.semantic_functions.prompt_template_config import (\n",
    "    PromptTemplateConfig,\n",
    ")\n",
    "from semantic_kernel.semantic_functions.semantic_function_config import (\n",
    "    SemanticFunctionConfig,\n",
    ")\n",
    "from semantic_kernel.skill_definition.read_only_skill_collection_base import (\n",
    "    ReadOnlySkillCollectionBase,\n",
    ")\n",
    "from semantic_kernel.skill_definition.skill_collection import SkillCollection\n",
    "from semantic_kernel.skill_definition.skill_collection_base import SkillCollectionBase\n",
    "from semantic_kernel.template_engine.prompt_template_engine_base import (\n",
    "    PromptTemplateEngineBase,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_create_semantic_function(\n",
    "    kernel, \n",
    "    skill_name: str,\n",
    "    function_name: str,\n",
    "    function_config: SemanticFunctionConfig,\n",
    ") -> SKFunctionBase:\n",
    "    function_type = function_config.prompt_template_config.type\n",
    "    if not function_type == \"completion\":\n",
    "        raise AIException(\n",
    "            AIException.ErrorCodes.FunctionTypeNotSupported,\n",
    "            f\"Function type not supported: {function_type}\",\n",
    "        )\n",
    "\n",
    "    function = SKFunction.from_semantic_config(\n",
    "        skill_name, function_name, function_config\n",
    "    )\n",
    "    function.request_settings.update_from_completion_config(\n",
    "        function_config.prompt_template_config.completion\n",
    "    )\n",
    "\n",
    "    # Connect the function to the current kernel skill\n",
    "    # collection, in case the function is invoked manually\n",
    "    # without a context and without a way to find other functions.\n",
    "    function.set_default_skill_collection(kernel.skills)\n",
    "\n",
    "    # TODO: allow to postpone this (use lazy init)\n",
    "    # allow to create semantic functions without\n",
    "    # a default backend\n",
    "    backend = kernel._config.get_completion_backend(\n",
    "        function_config.prompt_template_config.default_backends[0]\n",
    "        if len(function_config.prompt_template_config.default_backends) > 0\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    function.set_ai_configuration(\n",
    "        CompleteRequestSettings.from_completion_config(\n",
    "            function_config.prompt_template_config.completion\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if backend.backend_type == BackendType.AzureOpenAI:\n",
    "        Verify.not_null(\n",
    "            backend.azure_open_ai, \"Azure OpenAI configuration is missing\"\n",
    "        )\n",
    "        function.set_ai_backend(\n",
    "            lambda: AzureTextCompletion(\n",
    "                backend.azure_open_ai.deployment_name,  # type: ignore\n",
    "                backend.azure_open_ai.endpoint,  # type: ignore\n",
    "                backend.azure_open_ai.api_key,  # type: ignore\n",
    "                backend.azure_open_ai.api_version,  # type: ignore\n",
    "                kernel._log,\n",
    "            )\n",
    "        )\n",
    "    elif backend.backend_type == BackendType.OpenAI:\n",
    "        Verify.not_null(backend.open_ai, \"OpenAI configuration is missing\")\n",
    "        function.set_ai_backend(\n",
    "            lambda: OpenAITextCompletion(\n",
    "                backend.open_ai.model_id,  # type: ignore\n",
    "                backend.open_ai.api_key,  # type: ignore\n",
    "                backend.open_ai.org_id,  # type: ignore\n",
    "                kernel._log,\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise AIException(\n",
    "            AIException.ErrorCodes.InvalidConfiguration,\n",
    "            f\"Unknown/unsupported backend type: {backend.backend_type.name}, \"\n",
    "            f\"unable to prepare semantic function. Function description: \"\n",
    "            f\"{function_config.prompt_template_config.description}\",\n",
    "        )\n",
    "\n",
    "    return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_create_semantic_function(kernel, \"FunSkill\", \"Joke\", function_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
